# ai-trust-study
/* THIS CODE IS MY OWN WORK. IT WAS WRITTEN WITHOUT CONSULTING CODE WRITTEN BY OTHER STUDENTS OR RELYING SOLELY ON LARGE LANGUAGE MODELS SUCH AS CHATGPT. [Sunny Zheng] */
This repository contains the question set and AI response variations used in my CS 312 final project on how anthropomorphic design cues influence trust, confidence, and reliance on AI systems. The dataset includes 12 multiple-choice questions paired with six different AI “personas,” each representing a different level of anthropomorphism:
1. Minimal Bot – no human cues
2. Name Only – human-like name
3. Polite Tone – warm and friendly phrasing
4. Name + Avatar – human identity + social presence
5. Authority – includes explicit credibility or expertise cues (e.g., credentials, badges, or expert framing)
6. Uncertainty Signaling – explicitly communicates uncertainty or confidence calibration (e.g., hedging language or probability cues)
All six personas give the same factual answer to isolate the effect of presentation/design on user trust.
